"""
ì¿¼ë¦¬ ë¼ìš°í„° ì—ì´ì „íŠ¸ (LangChain Tool ê¸°ë°˜)
- 1ë‹¨ê³„: ì¿¼ë¦¬ ì „ì²˜ë¦¬ (Query Preprocessing)
- 2ë‹¨ê³„: LangChain Tool ìë™ ì„ íƒ â†’ MCP ì„œë²„ í˜¸ì¶œ (operation_id ë§¤ì¹­)
"""

from langchain_ollama import ChatOllama
from langchain.tools import BaseTool
from langchain_core.messages import HumanMessage, SystemMessage

import json
import httpx
import asyncio
from typing import Dict, Any, List

from core.config import settings
from schemas.mcp_router import PreprocessedQuery, RouteType, RoutingDecision


MCP_URL = settings.MCP_SERVER_URL  # http://[MCP_SERVER_IP]:[MCP_SERVER_PORT]/mcp

# --- LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ---
# ì „ì²˜ë¦¬ìš© LLM (ì •í™•ì„± ìš°ì„ )
preprocessing_llm = ChatOllama(
    model=settings.PREPROCESSING_MODEL_NAME or settings.OLLAMA_MODEL_NAME,
    base_url=settings.OLLAMA_BASE_URL,
    temperature=settings.PREPROCESSING_TEMPERATURE,
    request_timeout=60.0
)

# Tool ì„ íƒìš© LLM (ì¼ê´€ì„± ìš°ì„ )
tool_selector_llm = ChatOllama(
    model=settings.ROUTING_MODEL_NAME or settings.OLLAMA_MODEL_NAME,
    base_url=settings.OLLAMA_BASE_URL,
    temperature=settings.ROUTING_TEMPERATURE,
    request_timeout=60.0
)


# =====================================================
# 1ë‹¨ê³„: ì¿¼ë¦¬ ì „ì²˜ë¦¬ (Query Preprocessing)
# =====================================================

def _preprocess_query_internal(query: str) -> PreprocessedQuery:
    """
    ì‚¬ìš©ìì˜ ì›ë³¸ ì¿¼ë¦¬ë¥¼ ë²¡í„° ê²€ìƒ‰ì— ìµœì í™”ëœ í˜•íƒœë¡œ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    ìˆ˜í–‰ ì‘ì—…:
    - êµ¬ì–´ì²´ â†’ ê²€ìƒ‰ìš© í‘œì¤€ í‘œí˜„ìœ¼ë¡œ ë³€í™˜
    - í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
    - ì˜¤íƒ€ ìˆ˜ì • ë° ì•½ì–´ í•´ì†Œ
    - ë¶ˆí•„ìš”í•œ ì¡°ì‚¬/ì–´ë¯¸ ì œê±°
    
    Args:
        query: ì‚¬ìš©ìì˜ ì›ë³¸ ì¿¼ë¦¬
        
    Returns:
        PreprocessedQuery: ì „ì²˜ë¦¬ ê²°ê³¼ (ì •ì œëœ ì¿¼ë¦¬, í‚¤ì›Œë“œ, ì‹ ë¢°ë„)
    """
    
    print(f"\n{'='*60}")
    print(f"[1ë‹¨ê³„: ì¿¼ë¦¬ ì „ì²˜ë¦¬ ì‹œì‘]")
    print(f"ì›ë³¸ ì¿¼ë¦¬: {query}")
    print(f"{'='*60}")
    
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: ì „ì²˜ë¦¬ ì§€ì¹¨
    system_prompt = """ë‹¹ì‹ ì€ ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë²¡í„° ê²€ìƒ‰ì— ìµœì í™”ëœ í˜•íƒœë¡œ ì „ì²˜ë¦¬í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**ë‹¹ì‹ ì˜ ì„ë¬´**:
1. ì‚¬ìš©ìì˜ êµ¬ì–´ì²´ ì¿¼ë¦¬ë¥¼ ëª…í™•í•˜ê³  ê²€ìƒ‰ ê°€ëŠ¥í•œ í‘œì¤€ í‘œí˜„ìœ¼ë¡œ ë³€í™˜
2. í•µì‹¬ í‚¤ì›Œë“œë¥¼ 3~5ê°œ ì¶”ì¶œ (ì¹´ë“œ í˜œíƒ, ì†Œë¹„ íŒ¨í„´ ê´€ë ¨)
3. ì˜¤íƒ€ ìˆ˜ì •, ì•½ì–´ í•´ì†Œ, ë¶ˆí•„ìš”í•œ ì¡°ì‚¬ ì œê±°
4. ì „ì²˜ë¦¬ ê²°ê³¼ì˜ í’ˆì§ˆì„ 0.0~1.0ìœ¼ë¡œ í‰ê°€

**ì˜ˆì‹œ**:
ì…ë ¥: "20ëŒ€ ì—¬ì”ë° ì‡¼í•‘ ìì£¼í•¨"
ì¶œë ¥: 
{
  "normalized_query": "20ëŒ€ ì—¬ì„± ì‡¼í•‘ í• ì¸ ì¹´ë“œ ì¶”ì²œ",
  "key_keywords": ["20ëŒ€", "ì—¬ì„±", "ì‡¼í•‘", "í• ì¸", "ì¹´ë“œ"],
  "confidence": 0.85
}

ì…ë ¥: "í¸ì˜ì  ë§ì´ì”€ í• ì¸ë˜ëŠ”ê±°"
ì¶œë ¥:
{
  "normalized_query": "í¸ì˜ì  í• ì¸ ì¹´ë“œ ì¶”ì²œ",
  "key_keywords": ["í¸ì˜ì ", "í• ì¸", "ì¹´ë“œ", "ì¶”ì²œ"],
  "confidence": 0.9
}

**ì¤‘ìš” ê·œì¹™**:
- normalized_queryëŠ” ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±
- key_keywordsëŠ” ì •í™•íˆ 3~5ê°œ
- confidenceëŠ” ì „ì²˜ë¦¬ í’ˆì§ˆì— ëŒ€í•œ ìì‹ ê° (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
- ì‘ë‹µì€ ë°˜ë“œì‹œ JSON í˜•ì‹ë§Œ ì¶œë ¥ (ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ê¸ˆì§€)"""

    user_prompt = f"ë‹¤ìŒ ì¿¼ë¦¬ë¥¼ ì „ì²˜ë¦¬í•˜ì„¸ìš”:\n\n{query}"
    
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_prompt)
    ]
    
    try:
        # LLM í˜¸ì¶œ
        print(f"[ì „ì²˜ë¦¬ LLM í˜¸ì¶œ ì¤‘...]")
        response = preprocessing_llm.invoke(messages)
        raw_output = response.content
        
        print(f"[LLM ì›ë³¸ ì‘ë‹µ]\n{raw_output}\n")
        
        # JSON íŒŒì‹±
        # LLMì´ ```json ... ``` í˜•íƒœë¡œ ì‘ë‹µí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì²˜ë¦¬
        if "```json" in raw_output:
            json_str = raw_output.split("```json")[1].split("```")[0].strip()
        elif "```" in raw_output:
            json_str = raw_output.split("```")[1].split("```")[0].strip()
        else:
            json_str = raw_output.strip()
        
        parsed_data = json.loads(json_str)
        
        # PreprocessedQuery ê°ì²´ ìƒì„±
        result = PreprocessedQuery(
            original_query=query,
            normalized_query=parsed_data.get("normalized_query", query),
            key_keywords=parsed_data.get("key_keywords", []),
            confidence=float(parsed_data.get("confidence", 0.5))
        )
        
        print(f"[ì „ì²˜ë¦¬ ì™„ë£Œ]")
        print(f"âœ“ ì •ì œëœ ì¿¼ë¦¬: {result.normalized_query}")
        print(f"âœ“ í•µì‹¬ í‚¤ì›Œë“œ: {', '.join(result.key_keywords)}")
        print(f"âœ“ ì‹ ë¢°ë„: {result.confidence:.2f}")
        print(f"{'='*60}\n")
        
        return result
        
    except json.JSONDecodeError as e:
        print(f"[ì˜¤ë¥˜] JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        print(f"[í´ë°±] ì›ë³¸ ì¿¼ë¦¬ ì‚¬ìš©")
        
        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì¿¼ë¦¬ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì‹ ë¢°ë„ ë‚®ê²Œ)
        return PreprocessedQuery(
            original_query=query,
            normalized_query=query,
            key_keywords=[],
            confidence=0.3
        )
        
    except Exception as e:
        print(f"[ì˜¤ë¥˜] ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        print(f"[í´ë°±] ì›ë³¸ ì¿¼ë¦¬ ì‚¬ìš©")
        
        return PreprocessedQuery(
            original_query=query,
            normalized_query=query,
            key_keywords=[],
            confidence=0.0
        )


# =====================================================
# 2ë‹¨ê³„: MCP Tools ì •ì˜ (operation_id ë§¤ì¹­)
# =====================================================

# --- Tool 1: ì¹´ë“œ ì¶”ì²œ RAG Tool ---
class MCPCardRecommendationTool(BaseTool):
    name: str = "get_card_recommendation"  # MCP operation_idì™€ ì¼ì¹˜
    description: str = (
        "ì‚¬ìš©ìê°€ ì‹ ìš©ì¹´ë“œ/ì²´í¬ì¹´ë“œ ì¶”ì²œì„ ìš”ì²­í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤. "
        "'ì¹´ë“œ ì¶”ì²œ', 'í• ì¸ ì¹´ë“œ', 'ì‡¼í•‘ ì¹´ë“œ', 'í¸ì˜ì  ì¹´ë“œ', 'ì£¼ìœ  ì¹´ë“œ' ë“±ì˜ í‚¤ì›Œë“œ í¬í•¨ ì‹œ ì‚¬ìš©. "
        "ì‚¬ìš©ìì˜ ì†Œë¹„ íŒ¨í„´ì´ë‚˜ í•„ìš”í•œ í˜œíƒì„ queryë¡œ ë„˜ê¹ë‹ˆë‹¤."
    )
    
    def _run(self, query: str):
        """ë™ê¸° í˜¸ì¶œìš© (ë¹„ë™ê¸° ë˜í•‘)"""
        return asyncio.run(self._arun(query=query))
    
    async def _arun(self, query: str) -> str:
        """MCP ì„œë²„ì˜ ì¹´ë“œ ì¶”ì²œ RAG íŒŒì´í”„ë¼ì¸ì„ í˜¸ì¶œí•©ë‹ˆë‹¤."""
        
        # 1ë‹¨ê³„: ì¿¼ë¦¬ ì „ì²˜ë¦¬
        print(f"--- [CardTool] 1. ì¿¼ë¦¬ ì „ì²˜ë¦¬ ì‹œì‘ ---")
        preprocessed = _preprocess_query_internal(query)
        
        # 2ë‹¨ê³„: MCP ì„œë²„ í˜¸ì¶œ
        base_url = MCP_URL.replace('/mcp', '')
        endpoint_url = f"{base_url}/tools/card-recommendation"
        
        print(f"--- [CardTool] 2. MCP ì„œë²„ í˜¸ì¶œ: {endpoint_url} ---")
        print(f"--- [CardTool] ì •ì œëœ ì¿¼ë¦¬: {preprocessed.normalized_query} ---")
        
        async with httpx.AsyncClient() as client:
            try:
                response = await client.post(
                    endpoint_url,
                    json={
                        "query": preprocessed.normalized_query,
                        "retrieve_k": 5,
                        "final_k": 3
                    },
                    timeout=60.0
                )
                
                response.raise_for_status()
                result_data = response.json()
                
                answer = result_data.get("answer", "")
                context_docs = result_data.get("context_docs", [])
                
                # ë‹µë³€ í¬ë§·íŒ…
                formatted_response = answer
                if context_docs:
                    formatted_response += "\n\nğŸ“‹ ì°¸ê³  ì¹´ë“œ:"
                    for i, doc in enumerate(context_docs, 1):
                        card_name = doc.get("metadata", {}).get("card_name", "ì•Œ ìˆ˜ ì—†ìŒ")
                        formatted_response += f"\n{i}. {card_name}"
                
                print(f"--- [CardTool] 3. ì‘ë‹µ ì™„ë£Œ ---")
                return formatted_response
                
            except Exception as e:
                print(f"--- [CardTool] ERROR: {e} ---")
                return f"[ì¹´ë“œ ì¶”ì²œ ì˜¤ë¥˜: {e}]"


# --- Tool 2: ML ê¸°ë°˜ ì†Œë¹„ íŒ¨í„´ ë¶„ì„ Tool ---
class MCPMyDataAnalysisTool(BaseTool):
    name: str = "analyze_consumption_pattern"  # MCP operation_idì™€ ì¼ì¹˜ (ì˜ˆì •)
    description: str = (
        "ì‚¬ìš©ìì˜ ì†Œë¹„ íŒ¨í„´ì„ ë¶„ì„í•˜ê±°ë‚˜ í†µê³„ë¥¼ ì œê³µí•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤. "
        "'ì†Œë¹„ íŒ¨í„´', 'ì–´ë””ì— ëˆ ì“°ë‚˜', 'í†µê³„', 'ë¶„ì„í•´ì¤˜' ë“±ì˜ í‚¤ì›Œë“œ í¬í•¨ ì‹œ ì‚¬ìš©. "
        "MyData ê¸°ë°˜ ê°œì¸í™”ëœ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤."
    )
    
    def _run(self, query: str):
        """ë™ê¸° í˜¸ì¶œìš©"""
        return asyncio.run(self._arun(query=query))
    
    async def _arun(self, query: str) -> str:
        """ML ê¸°ë°˜ ì†Œë¹„ íŒ¨í„´ ë¶„ì„ (ë¯¸êµ¬í˜„)"""
        print(f"--- [MyDataTool] í˜¸ì¶œ: {query} ---")
        return "[ì†Œë¹„ íŒ¨í„´ ë¶„ì„ ê¸°ëŠ¥ì€ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤. ê³§ ì œê³µë  ì˜ˆì •ì…ë‹ˆë‹¤.]"


# --- Tool 3: QnA DB ì¡°íšŒ Tool ---
class MCPQnADatabaseTool(BaseTool):
    name: str = "query_faq_database"  # MCP operation_idì™€ ì¼ì¹˜ (ì˜ˆì •)
    description: str = (
        "ê°„ë‹¨í•œ ì •ë³´ ì¡°íšŒë‚˜ FAQ ì§ˆë¬¸ì— ë‹µë³€í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤. "
        "'ì´ë²¤íŠ¸ ì–¸ì œê¹Œì§€', 'í”„ë¡œëª¨ì…˜', 'ì‹ ì²­ ë°©ë²•', 'ê³ ê°ì„¼í„°', 'ì˜ì—…ì‹œê°„' ë“±ì˜ í‚¤ì›Œë“œ í¬í•¨ ì‹œ ì‚¬ìš©. "
        "ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë¹ ë¥´ê²Œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."
    )
    
    def _run(self, query: str):
        """ë™ê¸° í˜¸ì¶œìš©"""
        return asyncio.run(self._arun(query=query))
    
    async def _arun(self, query: str) -> str:
        """QnA DB ì¡°íšŒ (ë¯¸êµ¬í˜„)"""
        print(f"--- [QnATool] í˜¸ì¶œ: {query} ---")
        return "[FAQ ë°ì´í„°ë² ì´ìŠ¤ ê¸°ëŠ¥ì€ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤.]"


# =====================================================
# ê¸°ì¡´ ë¼ìš°íŒ… í•¨ìˆ˜ (íê¸° ì˜ˆì • - í˜¸í™˜ì„± ìœ ì§€ìš©)
# =====================================================

def route_query(preprocessed_query: PreprocessedQuery) -> RoutingDecision:
    """
    ì „ì²˜ë¦¬ëœ ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ë„êµ¬ë¡œ ë¼ìš°íŒ…í•©ë‹ˆë‹¤.
    
    ë¼ìš°íŒ… ê²½ë¡œ:
    - RAG_SEARCH: ì¹´ë“œ ì¶”ì²œ, ê¸ˆìœµ ìš©ì–´ ì„¤ëª… ë“± RAG ê²€ìƒ‰ í•„ìš”
    - ML_TOOL: ì†Œë¹„ íŒ¨í„´ ë¶„ì„, ì˜ˆì¸¡ ë“± ML ëª¨ë¸ í•„ìš”
    - QNA_DB: ê°„ë‹¨í•œ ì •ë³´ ì¡°íšŒ (ì´ë²¤íŠ¸, FAQ ë“±)
    - GENERAL: ì¼ë°˜ ëŒ€í™”, ì¸ì‚¬ ë“±
    
    Args:
        preprocessed_query: ì „ì²˜ë¦¬ëœ ì¿¼ë¦¬ ê°ì²´
        
    Returns:
        RoutingDecision: ë¼ìš°íŒ… ê²°ì • ê²°ê³¼ (ê²½ë¡œ, ì´ìœ , ì‹ ë¢°ë„)
    """
    
    print(f"\n{'='*60}")
    print(f"[2ë‹¨ê³„: ì¿¼ë¦¬ ë¼ìš°íŒ… ì‹œì‘]")
    print(f"ì •ì œëœ ì¿¼ë¦¬: {preprocessed_query.normalized_query}")
    print(f"í‚¤ì›Œë“œ: {', '.join(preprocessed_query.key_keywords)}")
    print(f"{'='*60}")
    
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: ë¼ìš°íŒ… ì§€ì¹¨
    system_prompt = """ë‹¹ì‹ ì€ ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì²˜ë¦¬ ê²½ë¡œë¡œ ë¼ìš°íŒ…í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**4ê°€ì§€ ë¼ìš°íŒ… ê²½ë¡œ**:

1. **RAG_SEARCH** - RAG ê²€ìƒ‰ (ë²¡í„° DB ê²€ìƒ‰ + LLM ìƒì„±)
   - ì¹´ë“œ ì¶”ì²œ: "í• ì¸ ì¹´ë“œ ì¶”ì²œ", "ì‡¼í•‘ ì¹´ë“œ ì•Œë ¤ì¤˜", "ì£¼ìœ  ì¹´ë“œ ë­ê°€ ì¢‹ì•„?"
   - ê¸ˆìœµ ìš©ì–´ ì„¤ëª…: "ì—°íšŒë¹„ê°€ ë­ì•¼?", "APRì´ë€?", "ì²´í¬ì¹´ë“œ ì‹ ìš©ì¹´ë“œ ì°¨ì´"
   - ì¹´ë“œ í˜œíƒ ì •ë³´: "ì´ ì¹´ë“œ í˜œíƒ ì•Œë ¤ì¤˜", "í• ì¸ìœ¨ ì–¼ë§ˆì•¼?"

2. **ML_TOOL** - ML ëª¨ë¸ (ë°ì´í„° ë¶„ì„, ì˜ˆì¸¡)
   - ì†Œë¹„ íŒ¨í„´ ë¶„ì„: "ë‚´ ì†Œë¹„ íŒ¨í„´ ë¶„ì„í•´ì¤˜", "ì–´ë””ì— ëˆ ë§ì´ ì“°ë‚˜?"
   - ì¶”ì²œ ì˜ˆì¸¡: "ë‚˜í•œí…Œ ë§ëŠ” ì¹´ë“œ ì˜ˆì¸¡í•´ì¤˜" (MyData ê¸°ë°˜)
   - í†µê³„ ë¶„ì„: "ì´ë²ˆ ë‹¬ ì†Œë¹„ í†µê³„"

3. **QNA_DB** - ê°„ë‹¨í•œ ì •ë³´ ì¡°íšŒ (DB ì¿¼ë¦¬)
   - ì´ë²¤íŠ¸ ì •ë³´: "ì´ë²¤íŠ¸ ì–¸ì œê¹Œì§€?", "í”„ë¡œëª¨ì…˜ ìˆì–´?"
   - FAQ: "ì¹´ë“œ ì‹ ì²­ ë°©ë²•", "ê³ ê°ì„¼í„° ë²ˆí˜¸"
   - ê°„ë‹¨í•œ ì‚¬ì‹¤ í™•ì¸: "ì˜ì—…ì‹œê°„", "ìˆ˜ìˆ˜ë£Œ ì–¼ë§ˆ?"

4. **GENERAL** - ì¼ë°˜ ëŒ€í™”
   - ì¸ì‚¬: "ì•ˆë…•", "ê³ ë§ˆì›Œ", "ë„ì™€ì¤˜"
   - ì¡ë‹´: "ë‚ ì”¨ ì¢‹ë„¤", "ì˜¤ëŠ˜ ë­í•˜ì§€?"
   - ê¸°íƒ€ ëŒ€í™”

**ì‘ë‹µ í˜•ì‹** (ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥):
{
  "route": "RAG_SEARCH" | "ML_TOOL" | "QNA_DB" | "GENERAL",
  "reason": "ì„ íƒ ì´ìœ ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ",
  "confidence": 0.0 ~ 1.0
}

**ì˜ˆì‹œ**:

ì…ë ¥: "20ëŒ€ ì—¬ì„± ì‡¼í•‘ í• ì¸ ì¹´ë“œ ì¶”ì²œ"
â†’ {"route": "RAG_SEARCH", "reason": "ì¹´ë“œ ì¶”ì²œ ìš”ì²­ìœ¼ë¡œ RAG ê²€ìƒ‰ í•„ìš”", "confidence": 0.95}

ì…ë ¥: "ë‚´ ì†Œë¹„ íŒ¨í„´ ë¶„ì„í•´ì¤˜"
â†’ {"route": "ML_TOOL", "reason": "ì†Œë¹„ íŒ¨í„´ ë¶„ì„ì€ ML ëª¨ë¸ í•„ìš”", "confidence": 0.9}

ì…ë ¥: "ì´ë²¤íŠ¸ ì–¸ì œê¹Œì§€?"
â†’ {"route": "QNA_DB", "reason": "ì´ë²¤íŠ¸ ì •ë³´ëŠ” DB ì¡°íšŒë¡œ ì¶©ë¶„", "confidence": 0.85}

ì…ë ¥: "ì•ˆë…•í•˜ì„¸ìš”"
â†’ {"route": "GENERAL", "reason": "ì¼ë°˜ ì¸ì‚¬ë§", "confidence": 1.0}

**ì¤‘ìš”**: 
- ì‘ë‹µì€ ë°˜ë“œì‹œ JSONë§Œ (ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ê¸ˆì§€)
- routeëŠ” ë°˜ë“œì‹œ ìœ„ 4ê°€ì§€ ì¤‘ í•˜ë‚˜
- confidenceëŠ” ê²°ì •ì— ëŒ€í•œ í™•ì‹ ë„"""

    # ì „ì²˜ë¦¬ëœ ì¿¼ë¦¬ ì •ë³´ë¥¼ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ì— í¬í•¨
    user_prompt = f"""ë‹¤ìŒ ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ê²½ë¡œë¡œ ë¼ìš°íŒ…í•˜ì„¸ìš”:

**ì •ì œëœ ì¿¼ë¦¬**: {preprocessed_query.normalized_query}
**í•µì‹¬ í‚¤ì›Œë“œ**: {', '.join(preprocessed_query.key_keywords)}
**ì›ë³¸ ì¿¼ë¦¬**: {preprocessed_query.original_query}"""

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_prompt)
    ]
    
    try:
        # LLM í˜¸ì¶œ
        print(f"[ë¼ìš°íŒ… LLM í˜¸ì¶œ ì¤‘...]")
        response = routing_llm.invoke(messages)
        raw_output = response.content
        
        print(f"[LLM ì›ë³¸ ì‘ë‹µ]\n{raw_output}\n")
        
        # JSON íŒŒì‹±
        if "```json" in raw_output:
            json_str = raw_output.split("```json")[1].split("```")[0].strip()
        elif "```" in raw_output:
            json_str = raw_output.split("```")[1].split("```")[0].strip()
        else:
            json_str = raw_output.strip()
        
        parsed_data = json.loads(json_str)
        
        # RouteType enumìœ¼ë¡œ ë³€í™˜
        route_str = parsed_data.get("route", "GENERAL")
        try:
            route = RouteType[route_str]
        except KeyError:
            print(f"[ê²½ê³ ] ì•Œ ìˆ˜ ì—†ëŠ” ê²½ë¡œ: {route_str}, GENERALë¡œ í´ë°±")
            route = RouteType.GENERAL
        
        # RoutingDecision ê°ì²´ ìƒì„±
        result = RoutingDecision(
            route=route,
            reason=parsed_data.get("reason", "ë¼ìš°íŒ… ê²°ì •"),
            confidence=float(parsed_data.get("confidence", 0.5)),
            preprocessed_query=preprocessed_query
        )
        
        print(f"[ë¼ìš°íŒ… ì™„ë£Œ]")
        print(f"âœ“ ì„ íƒëœ ê²½ë¡œ: {result.route.value}")
        print(f"âœ“ ì„ íƒ ì´ìœ : {result.reason}")
        print(f"âœ“ ì‹ ë¢°ë„: {result.confidence:.2f}")
        print(f"{'='*60}\n")
        
        return result
        
    except json.JSONDecodeError as e:
        print(f"[ì˜¤ë¥˜] JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        print(f"[í´ë°±] GENERAL ê²½ë¡œ ì‚¬ìš©")
        
        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ GENERALë¡œ í´ë°±
        return RoutingDecision(
            route=RouteType.GENERAL,
            reason="ë¼ìš°íŒ… íŒŒì‹± ì‹¤íŒ¨ë¡œ ì¼ë°˜ ëŒ€í™” ì²˜ë¦¬",
            confidence=0.3,
            preprocessed_query=preprocessed_query
        )
        
    except Exception as e:
        print(f"[ì˜¤ë¥˜] ë¼ìš°íŒ… ì‹¤íŒ¨: {e}")
        print(f"[í´ë°±] GENERAL ê²½ë¡œ ì‚¬ìš©")
        
        return RoutingDecision(
            route=RouteType.GENERAL,
            reason="ë¼ìš°íŒ… ì˜¤ë¥˜ë¡œ ì¼ë°˜ ëŒ€í™” ì²˜ë¦¬",
            confidence=0.0,
            preprocessed_query=preprocessed_query
        )


# =====================================================
# í†µí•© ì—ì´ì „íŠ¸ (weather_agent.AgentRunner ìŠ¤íƒ€ì¼)
# =====================================================

class QueryRouterAgent:
    """
    LangChain Tool ê¸°ë°˜ ì¿¼ë¦¬ ë¼ìš°í„° ì—ì´ì „íŠ¸
    
    ë™ì‘ ë°©ì‹:
    1. ì‚¬ìš©ì ì¿¼ë¦¬ ì…ë ¥
    2. LLMì´ ì ì ˆí•œ Tool ìë™ ì„ íƒ (get_card_recommendation, analyze_consumption_pattern ë“±)
    3. ì„ íƒëœ Tool ë‚´ë¶€ì—ì„œ ì¿¼ë¦¬ ì „ì²˜ë¦¬ ìˆ˜í–‰
    4. MCP ì„œë²„ í˜¸ì¶œ (operation_id ìë™ ë§¤ì¹­)
    5. ê²°ê³¼ ë°˜í™˜
    
    ì‚¬ìš© ì˜ˆì‹œ:
        agent = QueryRouterAgent()
        result = agent.run("í¸ì˜ì  ë§ì´ ì“°ëŠ”ë° í• ì¸ ì¹´ë“œ ì¶”ì²œí•´ì¤˜")
    """
    
    def __init__(self, tools: List[BaseTool]):
        """
        QueryRouterAgent ì´ˆê¸°í™”
        
        Args:
            tools: ì‚¬ìš©í•  Tool ë¦¬ìŠ¤íŠ¸ (MCP Tools)
        """
        self._llm = tool_selector_llm  # Tool ì„ íƒìš© LLM
        self._tools = {tool.name: tool for tool in tools}
        self._llm_with_tools = tool_selector_llm.bind_tools(tools)  # Tool ë°”ì¸ë”©
        
        print(f"\n{'='*60}")
        print(f"[QueryRouterAgent ì´ˆê¸°í™”]")
        print(f"Tool ì„ íƒ ëª¨ë¸: {settings.ROUTING_MODEL_NAME or settings.OLLAMA_MODEL_NAME}")
        print(f"ë“±ë¡ëœ Tools: {list(self._tools.keys())}")
        print(f"{'='*60}\n")
    
    def run(self, query: str) -> str:
        """
        [ë™ê¸°ì‹ ì‹¤í–‰]
        ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë°›ì•„ LLMì´ ìë™ìœ¼ë¡œ Toolì„ ì„ íƒí•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤.
        
        Args:
            query: ì‚¬ìš©ìì˜ ì›ë³¸ ì¿¼ë¦¬
            
        Returns:
            str: Tool ì‹¤í–‰ ê²°ê³¼ ë˜ëŠ” LLM ì§ì ‘ ë‹µë³€
        """
        
        print(f"\n{'#'*60}")
        print(f"[QueryRouterAgent ì‹¤í–‰ ì‹œì‘]")
        print(f"ì¿¼ë¦¬: {query}")
        print(f"{'#'*60}")
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: Tool ì„ íƒ ì§€ì¹¨
        system_message = (
            "ë‹¹ì‹ ì€ ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n\n"
            "ë„êµ¬ ì‚¬ìš© ê¸°ì¤€:\n"
            "- 'get_card_recommendation': ì¹´ë“œ ì¶”ì²œ ìš”ì²­ (í• ì¸ ì¹´ë“œ, ì‡¼í•‘ ì¹´ë“œ, í¸ì˜ì  ì¹´ë“œ ë“±)\n"
            "- 'analyze_consumption_pattern': ì†Œë¹„ íŒ¨í„´ ë¶„ì„ ìš”ì²­ (í†µê³„, ì–´ë””ì— ëˆ ì“°ë‚˜ ë“±)\n"
            "- 'query_faq_database': ê°„ë‹¨í•œ ì •ë³´ ì¡°íšŒ (ì´ë²¤íŠ¸, FAQ, ì‹ ì²­ ë°©ë²• ë“±)\n"
            "- ë„êµ¬ ì—†ì´ ì§ì ‘ ë‹µë³€: ì¼ë°˜ ëŒ€í™”, ì¸ì‚¬, ê°„ë‹¨í•œ ì§ˆë¬¸\n\n"
            "ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ ì •í™•íˆ íŒŒì•…í•˜ì—¬ ê°€ì¥ ì í•©í•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ê±°ë‚˜ ì§ì ‘ ë‹µë³€í•˜ì„¸ìš”."
        )
        
        messages = [
            SystemMessage(content=system_message),
            HumanMessage(content=query)
        ]
        
        try:
            print(f"--- [Agent] 1. LLM í˜¸ì¶œ (Tool ì„ íƒ) ---")
            response = self._llm_with_tools.invoke(messages)
            
            # Tool í˜¸ì¶œ ì—¬ë¶€ í™•ì¸
            if response.tool_calls:
                tool_call = response.tool_calls[0]
                tool_name = tool_call.get("name")
                tool_args = tool_call.get("args", {})
                
                print(f"--- [Agent] 2. Tool ì„ íƒë¨: {tool_name} ---")
                print(f"--- [Agent] ì¸ì: {tool_args} ---")
                
                if tool_name in self._tools:
                    # Tool ì‹¤í–‰
                    result = self._tools[tool_name].run(**tool_args)
                    
                    print(f"--- [Agent] 3. Tool ì‹¤í–‰ ì™„ë£Œ ---")
                    print(f"{'#'*60}\n")
                    
                    return result
                else:
                    print(f"--- [Agent] ERROR: ì•Œ ìˆ˜ ì—†ëŠ” Tool '{tool_name}' ---")
                    return f"[ì˜¤ë¥˜: '{tool_name}' ë„êµ¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.]"
            
            # Tool ì—†ì´ ì§ì ‘ ë‹µë³€
            print(f"--- [Agent] 2. LLM ì§ì ‘ ë‹µë³€ ---")
            direct_answer = str(response.content)
            
            print(f"--- [Agent] 3. ë‹µë³€ ì™„ë£Œ ---")
            print(f"{'#'*60}\n")
            
            return direct_answer
            
        except Exception as e:
            print(f"\n{'!'*60}")
            print(f"[QueryRouterAgent ì˜¤ë¥˜]")
            print(f"ì˜¤ë¥˜: {e}")
            print(f"{'!'*60}\n")
            
            return f"[ì—ì´ì „íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}]"


# --- Tool ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ---
card_tool = MCPCardRecommendationTool()
mydata_tool = MCPMyDataAnalysisTool()
qna_tool = MCPQnADatabaseTool()

# --- ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ---
query_router_agent = QueryRouterAgent(tools=[card_tool, mydata_tool, qna_tool])
